{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNN Architectures\n",
    "\n",
    "## Case Studies \n",
    "The following are the primary four main architectures that are widely used in the research field today.\n",
    "\n",
    "### LeNet-5 [LeCun et al. 1998]\n",
    "This architecture was very successfully applied to hand written digit recognition in the late 90s. \n",
    "\n",
    "CONV - POOL - CONV - POOL - FC - FC\n",
    "\n",
    "Each convolution filters were 5x5 with stride of 1.\n",
    "\n",
    "### AlexNet [Krizhevsky et al. 2012]\n",
    "The first large scale convolutional neural network that was able to do well on the ImageNet classification task.\n",
    "\n",
    "CONV - MAX POOL - NORM - CONV - MAX POOL - NORM - CONV - CONV - CONV - MAX POOL - FC - FC - FC\n",
    "\n",
    "The input is of shape (N, 227, 227, 3), first layer of convolution has 96 11x11 filters applied at `stride=4`, thus, the output is of shape (N, 55, 55, 96) with 35,000 parameters. \n",
    "\n",
    "|Layer  |Output Dim.| Filter   | Stride | Pad | \n",
    "|-------|-----------|----------|--------|-----|\n",
    "|Input  | 227x227x3 |          |        |     |\n",
    "|CONV   | 55x55x96  | 96 11x11 | 4      | 0   |\n",
    "|MAXPOOL| 27x27x96  | 3x3      | 2      |     |\n",
    "|NORM   | 27x27x96  |          |        |     |\n",
    "|CONV   | 27x27x256 | 256 5x5  | 1      | 2   |\n",
    "|MAXPOOL| 13x13x256 | 3x3      | 2      |     |\n",
    "|NORM   | 13x13x256 |          |        |     |\n",
    "|CONV   | 13x13x384 | 384 3x3  | 1      | 1   | \n",
    "|CONV   | 13x13x384 | 384 3x3  | 1      | 1   |\n",
    "|CONV   | 13x13x256 | 256 3x3  | 1      | 1   |\n",
    "|MAXPOOL| 6x6x256   | 3x3      | 2      |     |\n",
    "|FC     | 4096      |          |        |     |\n",
    "|FC     | 4096      |          |        |     |\n",
    "|FC     | 1000      |          |none    |none |\n",
    "\n",
    "### VGGNet\n",
    "The idea is that smaller filters but deeper networks. AlexNet had 8 layers but VGG has up to 16~19 layers using the VGG16 architecture. The convolution filter is only 3x3 with stride of 1 and padding of 1. Also the max pooling layer is only 2x2 with stride of 2.\n",
    "\n",
    "#### Why use smaller filters (3x3)? \n",
    "Stack of three 3x3 convolution with stride 1 layers has the same effective receptive field as one 7x7 convolution layer. Here's a diagram that will illustrate the idea:\n",
    "\n",
    "Assuming we are looking at 1 dimension, along x-axis, sliding a 3x3 filter across 7 pixels. with `stride = 1`\n",
    "```\n",
    "1st Layer: = = = = = = =  \n",
    "2nd Layer:   = = = = =\n",
    "3rd Layer:     = = = \n",
    "Final:           =\n",
    "```\n",
    "\n",
    "This is equivalent to \n",
    "```\n",
    "1st Layer: = = = = = = =\n",
    "Final:           =\n",
    "```\n",
    "\n",
    "#### VGG 16\n",
    "* Input\n",
    "* 64 3x3 conv\n",
    "* 64 3x3 conv\n",
    "* Pool\n",
    "* 128 3x3 conv\n",
    "* 128 3x3 conv\n",
    "* Pool\n",
    "* 256 3x3 conv\n",
    "* 256 3x3 conv\n",
    "* Pool\n",
    "* 512 3x3 conv\n",
    "* 512 3x3 conv\n",
    "* 512 3x3 conv\n",
    "* Pool\n",
    "* FC 4096\n",
    "* FC 4096\n",
    "* FC 1000\n",
    "* Softmax\n",
    "\n",
    "### GoogleNet\n",
    "Deeper network with computational efficiency. \n",
    "\n",
    "* 22 layers\n",
    "* Efficient \"Inception\" module\n",
    "    * Design a good local network topology (network within network) and then stack these modules on top of each other\n",
    "* No FC layers\n",
    "* Only 5 million parameters, 12x less than AlexNet!\n",
    "* 6.7% error only on ImageNet task\n",
    "\n",
    "However, each inception module creates challenge for computational complexity. For example, we have an input of 28x28x256 to an inception module which has 1x1 conv, 3x3 conv, 5x5 conv, and 3x3 pool layers. Each of these layers will produce an output 28x28x128, 28x28x192, 28x28x96, 28x28x256. Then these outputs are conconcatenated together depth wise. We maintain the spatial dimension using zero padding. However, now the depth blows up. \n",
    "\n",
    "**Solution**: Use bottneneck filters, which is a 1x1 conv layer that is inserted before 3x3 conv and 5x5 conv. These 1x1 conv layer will project the feature depth to lower dimension. For example, a 64 1x1 conv on a 28x28x256 input will create an output of 28x28x64\n",
    "\n",
    "![inception](inception.png)\n",
    "\n",
    "Now you just stack all these inception modules together to create a deep network.\n",
    "\n",
    "### ResNet\n",
    "Extremely deep network using this residual connections.\n",
    "\n",
    "What happens when we continue stacking deeper layers on a *plain* convolutional neural network?\n",
    "The network **DOES NOT** perform better!\n",
    "\n",
    "![deepstack](deepstack.png)\n",
    "\n",
    "It is not caused by overfitting. It is an optimization problem. Deeper network is just harder to optimize. The deeper model should be able to perform at least as well as the shallower model. A solution by construction is copying the learned layers from the shallower model and setting additional layers to identity mapping. Use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping.\n",
    "\n",
    "Training ResNet in practice:\n",
    "\n",
    "* Batch normalization after every CONV layer\n",
    "* Xavier/2 initialization\n",
    "* SGD with momentum 0.9\n",
    "* Learning rate is about 0.1 and divide by 10 when validation error plateaus\n",
    "* Mini-batch size is 256\n",
    "* Weight decay is 1e-5\n",
    "* No dropout used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
