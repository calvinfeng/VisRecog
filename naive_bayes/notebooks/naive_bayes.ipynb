{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Naive Bayesian Network \n",
    "\n",
    "## Introduction\n",
    "Using the Enron email data set, we will create a Naive Bayesian network in this simple exercise to classify whether a given email is a spam or ham by looking at its word frequency as feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Mathematics\n",
    "### Definitions\n",
    "\n",
    "Let's define $N$ to be the number of total emails we have in the dataset and $N_{s}$ to be the number of spam emails in the email set.\n",
    "\n",
    "$N_{so}$ is the number of spam emails that contain the word \"offer\"\n",
    "\n",
    "$N_{o}$ is the number of emails that contain the word \"offer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then the probability of having a spam email in the set is said to be:\n",
    "\n",
    "$$\n",
    "P(SPAM=1) = \\frac{N_{s}}{N}\n",
    "$$ \n",
    "\n",
    "And the probability of having an email that contains the word *offer* is:\n",
    "\n",
    "$$\n",
    "P(OFFER=1) = \\frac{N_{o}}{N}\n",
    "$$\n",
    "\n",
    "Finally, the conditional probability of an email being a spam email given that it contains the word *offer*:\n",
    "\n",
    "$$\n",
    "P(SPAM=1\\mid OFFER=1) := \\frac{N_{so}}{N_{o}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Postulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If the probability of finding the word *offer* given that it's a spam email is higher than that of finding the word *offer* in a non-spam email:\n",
    "\n",
    "$$\n",
    "P(OFFER =1 \\mid SPAM=1)  > P(OFFER = 1 \\mid SPAM=0)\n",
    "$$\n",
    "\n",
    "then we can infer that:\n",
    "\n",
    "$$\n",
    "P(SPAM=1 \\mid OFFER=1) > P(SPAM = 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "P(SPAM=1 \\mid OFFER=1) = \\frac{P(OFFER=1 \\mid SPAM=1)P(SPAM=1)}{P(OFFER=1)} = \\frac{\\frac{N_{so}}{N_{s}}\\frac{N_{s}}{N}}{\\frac{N_{o}}{N}} = \\frac{N_{so}}{N_{o}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is known as the **Bayes' rule**, famously stated as $P(A \\mid B)=\\frac{P(B \\mid A)P(A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "P(SPAM=0 \\mid OFFER=1) = \\frac{P(OFFER=1 \\mid SPAM=0)P(SPAM=0)}{P(OFFER=1)} \\\\\n",
    "P(SPAM=1 \\mid OFFER=1) = \\frac{P(OFFER=1 \\mid SPAM=1)P(SPAM=1)}{P(OFFER=1)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For abbreviation, let's define that:\n",
    "\n",
    "$$\n",
    "P(SPAM=1) := P(S) \\\\\n",
    "P(OFFER=1 \\mid SPAM=1) := P(O \\mid S) \\\\\n",
    "P(OFFER=1 \\mid SPAM=0) := P(O \\mid S_{c}) \\\\\n",
    "P(SPAM=1 \\mid OFFER=1):= P(S \\mid O)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Begin with\n",
    "\n",
    "$$\n",
    "P(O \\mid S) > P(O \\mid S_{c})\n",
    "$$\n",
    "\n",
    "Rewrite them using **Bayes' rule**:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid O) P(O)}{P(S)} > \\frac{P(S_{c} \\mid O)P(O)}{P(S_{c})}\n",
    "$$\n",
    "\n",
    "The $P(O)$ terms cancel out each other:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid O)}{P(S)} > \\frac{P(S_{c} \\mid O)}{P(S_{c})}\n",
    "$$\n",
    "\n",
    "By definition, we can rewrite the right hand side as the following:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid O)}{P(S)} > \\frac{1 - P(S \\mid O)}{1 - P(S)}\n",
    "$$\n",
    "\n",
    "Re-organize the terms:\n",
    "\n",
    "$$\n",
    "\\frac{1 - P(S)}{P(S)} > \\frac{1 - P(S \\mid O)}{P(S \\mid O)}\n",
    "$$\n",
    "\n",
    "Then we can easily see that:\n",
    "\n",
    "$$\n",
    "\\frac{1}{P(S)} - 1 > \\frac{1}{P(S \\mid O)} - 1 \\\\\n",
    "\\frac{1}{P(S)} > \\frac{1}{P(S \\mid O)} \\\\\n",
    "$$\n",
    "\n",
    "**Q.E.D.**\n",
    "$$\n",
    "P(S \\mid O) > P(S)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Probability\n",
    "First of all, we load the data into a class object called `EmailSet` and compute the feature probability for each word that has appeared in the email using `FeatureProbability.from_email_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already processed!\n",
      "Feature probability set has 3672 ham emails.\n",
      "Feature probability set has 1500 spam emails.\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes.email_set import EmailSet\n",
    "from naive_bayes.email_set import build_and_save_email_set\n",
    "from naive_bayes.feature_prob_set import FeatureProbabilitySet\n",
    "\n",
    "# If you haven't pickled it, then run \n",
    "build_and_save_email_set()\n",
    "\n",
    "es = EmailSet.get()\n",
    "fps = FeatureProbabilitySet.from_email_set(es)\n",
    "\n",
    "print \"Feature probability set has %s ham emails.\" % fps.class_count.ham_count\n",
    "print \"Feature probability set has %s spam emails.\" % fps.class_count.spam_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:3751 with count: {'spam_count': 141, 'ham_count': 61}\n",
      "Prob ratio: 5.65849180328\n"
     ]
    }
   ],
   "source": [
    "code = es.word_encoding_dictionary.word_to_code(\"offer\")\n",
    "print \"Code:%s with count: %s\" % (code, fps.code_count[code])\n",
    "print \"Prob ratio: %s\" % fps.code_prob_ratio(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:14526 with count: {'spam_count': 0, 'ham_count': 1}\n",
      "Prob ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "code = es.word_encoding_dictionary.word_to_code(\"compensating\")\n",
    "print \"Code:%s with count: %s\" % (code, fps.code_count[code])\n",
    "print \"Prob ratio: %s\" % fps.code_prob_ratio(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:20347 with count: {'spam_count': 1, 'ham_count': 0}\n",
      "Prob ratio: inf\n"
     ]
    }
   ],
   "source": [
    "code = es.word_encoding_dictionary.word_to_code(\"bacterial\")\n",
    "print \"Code:%s with count: %s\" % (code, fps.code_count[code])\n",
    "print \"Prob ratio: %s\" % fps.code_prob_ratio(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that the word *bacterial* and *compensating* have rare occurence in the data set. The probability we compute has a very noisy estimate for their true value. In other words, they are statistically insignificant for us to draw any reliable conclusion. It is not safe to make the assumption that every email with teh word *bacterial* is a spam email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Filter Low-reach Features\n",
    "Let's apply a limit to filter the words that have very low occurence in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Spam Features\n",
      "18629 | 2004 | {'spam_count': 121, 'ham_count': 1} | 296.208\n",
      "2252 | microsoft | {'spam_count': 98, 'ham_count': 11} | 21.8094545455\n",
      "5912 | investment | {'spam_count': 96, 'ham_count': 11} | 21.3643636364\n",
      "2993 | results | {'spam_count': 98, 'ham_count': 18} | 13.328\n",
      "4144 | v | {'spam_count': 134, 'ham_count': 26} | 12.6166153846\n",
      "1123 | million | {'spam_count': 97, 'ham_count': 20} | 11.8728\n",
      "4335 | stop | {'spam_count': 147, 'ham_count': 31} | 11.6082580645\n",
      "6730 | software | {'spam_count': 101, 'ham_count': 22} | 11.2385454545\n",
      "2189 | 80 | {'spam_count': 104, 'ham_count': 23} | 11.0692173913\n",
      "515 | dollars | {'spam_count': 113, 'ham_count': 26} | 10.6393846154\n",
      "1035 | remove | {'spam_count': 110, 'ham_count': 28} | 9.61714285714\n",
      "7768 | stock | {'spam_count': 84, 'ham_count': 22} | 9.34690909091\n",
      "6072 | removed | {'spam_count': 83, 'ham_count': 22} | 9.23563636364\n",
      "674 | money | {'spam_count': 187, 'ham_count': 50} | 9.15552\n",
      "1089 | world | {'spam_count': 124, 'ham_count': 34} | 8.928\n",
      "3351 | save | {'spam_count': 125, 'ham_count': 35} | 8.74285714286\n",
      "201 | http | {'spam_count': 475, 'ham_count': 135} | 8.61333333333\n",
      "3868 | quality | {'spam_count': 101, 'ham_count': 29} | 8.52579310345\n",
      "5253 | canada | {'spam_count': 79, 'ham_count': 23} | 8.40834782609\n",
      "4643 | low | {'spam_count': 106, 'ham_count': 31} | 8.37058064516\n",
      "\n",
      "\n",
      "Best Ham Features\n",
      "3 | meter | {'spam_count': 0, 'ham_count': 773} | 0.0\n",
      "27 | cotten | {'spam_count': 0, 'ham_count': 157} | 0.0\n",
      "38 | aimee | {'spam_count': 0, 'ham_count': 121} | 0.0\n",
      "42 | daren | {'spam_count': 0, 'ham_count': 1030} | 0.0\n",
      "48 | fyi | {'spam_count': 0, 'ham_count': 277} | 0.0\n",
      "91 | mmbtu | {'spam_count': 0, 'ham_count': 527} | 0.0\n",
      "105 | hpl | {'spam_count': 0, 'ham_count': 1098} | 0.0\n",
      "113 | hplno | {'spam_count': 0, 'ham_count': 107} | 0.0\n",
      "115 | xls | {'spam_count': 0, 'ham_count': 504} | 0.0\n",
      "230 | sitara | {'spam_count': 0, 'ham_count': 405} | 0.0\n",
      "235 | pops | {'spam_count': 0, 'ham_count': 102} | 0.0\n",
      "2284 | scheduling | {'spam_count': 0, 'ham_count': 129} | 0.0\n",
      "242 | volumes | {'spam_count': 0, 'ham_count': 437} | 0.0\n",
      "325 | pat | {'spam_count': 0, 'ham_count': 249} | 0.0\n",
      "326 | clynes | {'spam_count': 0, 'ham_count': 184} | 0.0\n",
      "328 | enron | {'spam_count': 0, 'ham_count': 1462} | 0.0\n",
      "379 | nominations | {'spam_count': 0, 'ham_count': 133} | 0.0\n",
      "411 | hplc | {'spam_count': 0, 'ham_count': 124} | 0.0\n",
      "420 | hsc | {'spam_count': 0, 'ham_count': 134} | 0.0\n",
      "453 | 6353 | {'spam_count': 0, 'ham_count': 112} | 0.0\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes.feature_prob_selector import FeatureProbabilitySelector\n",
    "fps = FeatureProbabilitySet.from_email_set(es).filter_low_reach(limit=100)\n",
    "best_spam_features = FeatureProbabilitySelector.best_spam_features(fps)\n",
    "best_ham_features = FeatureProbabilitySelector.best_ham_features(fps)\n",
    "\n",
    "print \"Best Spam Features\"\n",
    "FeatureProbabilitySelector.print_feature_list(best_spam_features, es.word_encoding_dictionary)\n",
    "print \"\\n\"\n",
    "print \"Best Ham Features\"\n",
    "FeatureProbabilitySelector.print_feature_list(best_ham_features, es.word_encoding_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconditional Independence\n",
    "Two variables are unconditionally independent, if knowing the result of one tells nothing of the other under any circumstance.\n",
    "\n",
    "For example, let `H` to be the event of flipping a head, and `S` to be the event of rolling a 6.\n",
    "\n",
    "$$\n",
    "P(S \\wedge  H) = P(S)P(H) \\\\\n",
    "P(H \\mid S) = P(H) \\\\\n",
    "P(S \\wedge H) = P(S)P(H \\mid S) = P(S)P(H)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
